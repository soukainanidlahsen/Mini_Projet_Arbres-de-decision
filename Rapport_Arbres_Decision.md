# ğŸ“Š Rapport de Projet : Arbres de DÃ©cision, Extensions et Applications

**AnnÃ©e universitaire :** 2024-2025  
**Auteur :** Projet Data Mining  
**Date :** 31 DÃ©cembre 2024

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Introduction](#introduction)
2. [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
3. [Partie 1 : Concepts ThÃ©oriques](#partie-1--concepts-thÃ©oriques)
4. [Partie 2 : ImplÃ©mentation From Scratch](#partie-2--implÃ©mentation-from-scratch)
5. [Partie 3 : Extensions et ExpÃ©rimentations](#partie-3--extensions-et-expÃ©rimentations)
6. [Partie 4 : Application MÃ©tier](#partie-4--application-mÃ©tier)
7. [Conclusion](#conclusion)

---

## Introduction

Ce projet explore en profondeur les **arbres de dÃ©cision**, une mÃ©thode fondamentale de l'apprentissage automatique supervisÃ©. Il combine thÃ©orie, implÃ©mentation pratique et application rÃ©elle sur un cas de diagnostic mÃ©dical.

### Objectifs du Projet

- Comprendre les fondements mathÃ©matiques des arbres de dÃ©cision
- ImplÃ©menter un algorithme d'arbre de dÃ©cision "from scratch"
- Analyser le phÃ©nomÃ¨ne de sur-apprentissage
- Comparer diffÃ©rentes mÃ©thodes d'ensemble (Random Forest, AdaBoost)
- Appliquer ces techniques Ã  un problÃ¨me rÃ©el de classification

---

## Technologies UtilisÃ©es

| BibliothÃ¨que | Version | Utilisation |
|--------------|---------|-------------|
| **Python** | 3.x | Langage de programmation |
| **NumPy** | - | Calculs numÃ©riques et manipulation de tableaux |
| **Pandas** | - | Manipulation et analyse de donnÃ©es |
| **Matplotlib** | - | Visualisation graphique |
| **Scikit-learn** | - | Algorithmes ML de rÃ©fÃ©rence |

### Modules Scikit-learn UtilisÃ©s

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
```

---

## Partie 1 : Concepts ThÃ©oriques

### 1.1 Classification SupervisÃ©e

La classification supervisÃ©e est une technique d'apprentissage automatique oÃ¹ :

- On dispose d'un ensemble d'exemples **(x, y)** avec **x** les attributs et **y** la classe
- Le but est d'apprendre une fonction **f** telle que **f(x)** prÃ©dit **y**
- L'apprentissage est "supervisÃ©" car on connaÃ®t les vraies classes

### 1.2 Structure d'un Arbre de DÃ©cision

Un arbre de dÃ©cision est une structure hiÃ©rarchique composÃ©e de :

| Ã‰lÃ©ment | Description | Exemple |
|---------|-------------|---------|
| **NÅ“uds internes** | Test sur un attribut | `age > 30 ?` |
| **Branches** | RÃ©sultats du test | Oui / Non |
| **Feuilles** | PrÃ©diction de classe | Classe A / Classe B |

### 1.3 Mesures d'ImpuretÃ©

L'impuretÃ© mesure l'hÃ©tÃ©rogÃ©nÃ©itÃ© des classes dans un nÅ“ud. Trois mesures principales sont Ã©tudiÃ©es :

#### Indice de Gini

$$Gini(p) = 1 - \sum_{i=1}^{C} p_i^2$$

- Valeur entre 0 (pur) et 0.5 (Ã©quilibrÃ© pour 2 classes)
- CritÃ¨re par dÃ©faut dans scikit-learn
- Rapide Ã  calculer

#### Entropie

$$H(p) = -\sum_{i=1}^{C} p_i \log_2(p_i)$$

- Valeur entre 0 (pur) et 1 (Ã©quilibrÃ© pour 2 classes)
- Base du gain d'information (Information Gain)
- UtilisÃ© dans l'algorithme ID3/C4.5

#### Erreur de Classification

$$E(p) = 1 - \max(p_i)$$

- Mesure la plus simple
- Moins sensible aux variations de probabilitÃ©s
- Rarement utilisÃ© en pratique

### 1.4 ImplÃ©mentation des Fonctions d'ImpuretÃ©

```python
def gini(counts):
    """Calcule l'indice de Gini pour une distribution de classes."""
    counts = np.array(counts)
    total = np.sum(counts)
    if total == 0:
        return 0
    proportions = counts / total
    return 1 - np.sum(proportions ** 2)

def entropy(counts):
    """Calcule l'entropie pour une distribution de classes."""
    counts = np.array(counts)
    total = np.sum(counts)
    if total == 0:
        return 0
    proportions = counts / total
    proportions = proportions[proportions > 0]
    return -np.sum(proportions * np.log2(proportions))

def classification_error(counts):
    """Calcule l'erreur de classification pour une distribution de classes."""
    counts = np.array(counts)
    total = np.sum(counts)
    if total == 0:
        return 0
    proportions = counts / total
    return 1 - np.max(proportions)
```

### 1.5 Exemples NumÃ©riques

| Cas | Distribution | Gini | Entropie | Erreur |
|-----|--------------|------|----------|--------|
| Ã‰quilibrÃ© | [10, 10] | 0.5000 | 1.0000 | 0.5000 |
| TrÃ¨s pur | [18, 2] | 0.1800 | 0.4690 | 0.1000 |
| Cas 9/1 | [9, 1] | 0.1800 | 0.4690 | 0.1000 |
| Cas 5/5 | [5, 5] | 0.5000 | 1.0000 | 0.5000 |
| Cas 1/9 | [1, 9] | 0.1800 | 0.4690 | 0.1000 |

**Observation clÃ©** : Plus un nÅ“ud est pur (dominÃ© par une classe), plus son impuretÃ© est faible.

---

## Partie 2 : ImplÃ©mentation From Scratch

### 2.1 Dataset PÃ©dagogique : CrÃ©dit SimplifiÃ©

Un dataset fictif pour illustrer le fonctionnement de l'algorithme :

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Nombre d'exemples** | 12 |
| **Nombre d'attributs** | 4 |
| **Variables** | PropriÃ©taire, Ã‰tat Matrimonial, Revenu, DÃ©faut PrÃ©cÃ©dent |
| **Classes** | RefusÃ© (0), AccordÃ© (1) |

```python
data = np.array([
    [1, 1, 50, 0],  # Proprio, Matrimonial, Revenu, DÃ©faut
    [0, 0, 30, 1],
    [1, 2, 45, 0],
    # ... 12 exemples au total
])
labels = np.array([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0])
```

### 2.2 Structure de NÅ“ud

```python
class Node:
    def __init__(self):
        self.is_leaf = False        # Est-ce une feuille ?
        self.prediction = None      # Classe prÃ©dite (si feuille)
        self.feature_index = None   # Index de l'attribut de split
        self.threshold = None       # Seuil de dÃ©cision
        self.left = None            # Sous-arbre gauche
        self.right = None           # Sous-arbre droit
        self.gini = None            # ImpuretÃ© du nÅ“ud
        self.samples = None         # Nombre d'exemples
```

### 2.3 Fonction de Recherche du Meilleur Split

L'algorithme teste toutes les combinaisons (attribut, seuil) possibles :

**Pour les variables continues :**
- Trie des valeurs uniques
- Test des seuils Ã  mi-chemin entre valeurs consÃ©cutives

**Pour les variables catÃ©gorielles :**
- Test de chaque valeur unique comme critÃ¨re de split

```python
def find_best_split(X, y, feature_types):
    # Calcul du Gini parent
    parent_gini = gini(get_class_counts(y))
    
    best_gain = 0
    best_feature = None
    best_threshold = None
    
    for feature_idx in range(n_features):
        # Test de tous les seuils possibles
        for thresh in thresholds:
            # Calcul du gain d'information
            gain = parent_gini - weighted_gini
            
            if gain > best_gain:
                best_gain = gain
                best_feature = feature_idx
                best_threshold = thresh
    
    return best_feature, best_threshold, best_gain
```

### 2.4 Construction RÃ©cursive de l'Arbre

```python
def build_tree(X, y, feature_types, depth=0, max_depth=None, min_samples_leaf=1):
    node = Node()
    
    # Conditions d'arrÃªt
    if len(np.unique(y)) == 1:           # NÅ“ud pur
        return create_leaf(y)
    if max_depth and depth >= max_depth:  # Profondeur max atteinte
        return create_leaf(y)
    if len(y) < 2 * min_samples_leaf:     # Pas assez d'exemples
        return create_leaf(y)
    
    # Recherche du meilleur split
    best_feature, best_threshold, best_gain = find_best_split(X, y, feature_types)
    
    if best_gain <= 0:
        return create_leaf(y)
    
    # Construction rÃ©cursive des sous-arbres
    node.left = build_tree(X_left, y_left, ...)
    node.right = build_tree(X_right, y_right, ...)
    
    return node
```

### 2.5 Fonction de PrÃ©diction

```python
def predict_one(node, x, feature_types):
    if node.is_leaf:
        return node.prediction
    
    feature_val = x[node.feature_index]
    
    if feature_types[node.feature_index] == 'continuous':
        if feature_val <= node.threshold:
            return predict_one(node.left, x, feature_types)
        else:
            return predict_one(node.right, x, feature_types)
    else:  # categorical
        if feature_val == node.threshold:
            return predict_one(node.left, x, feature_types)
        else:
            return predict_one(node.right, x, feature_types)
```

### 2.6 Comparaison avec Scikit-learn

| MÃ©trique | Mini-arbre | Scikit-learn |
|----------|------------|--------------|
| PrÃ©cision entraÃ®nement | ~100% | ~100% |
| Temps d'exÃ©cution | Plus lent | OptimisÃ© |
| FonctionnalitÃ©s | Base | ComplÃ¨tes |

---

## Partie 3 : Extensions et ExpÃ©rimentations

### 3.1 Dataset RÃ©el : Breast Cancer Wisconsin

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| **Nombre d'exemples** | 569 |
| **Nombre d'attributs** | 30 |
| **Classes** | Maligne (0), BÃ©nigne (1) |
| **Distribution** | ~37% Malignes, ~63% BÃ©nignes |

**Attributs** : CaractÃ©ristiques cellulaires (rayon, texture, pÃ©rimÃ¨tre, aire, lissage, compacitÃ©, concavitÃ©, symÃ©trie, dimension fractale) - moyennes, erreurs standards, et "pires" valeurs.

### 3.2 Division Train/Test

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)
```

| Ensemble | Taille |
|----------|--------|
| Train | 398 (70%) |
| Test | 171 (30%) |

### 3.3 Analyse de l'Effet de la Profondeur

| max_depth | Train Acc | Test Acc | Ã‰cart |
|-----------|-----------|----------|-------|
| 1 | ~0.91 | ~0.90 | ~0.01 |
| 2 | ~0.94 | ~0.92 | ~0.02 |
| 3 | ~0.96 | ~0.93 | ~0.03 |
| 4 | ~0.98 | ~0.94 | ~0.04 |
| 5 | ~0.99 | ~0.93 | ~0.06 |
| 7 | ~1.00 | ~0.92 | ~0.08 |
| 10 | ~1.00 | ~0.91 | ~0.09 |
| None | ~1.00 | ~0.90 | ~0.10 |

### 3.4 PhÃ©nomÃ¨ne de Sur-apprentissage (Overfitting)

**Observations :**

1. â¬†ï¸ Quand `max_depth` augmente â†’ PrÃ©cision train augmente (jusqu'Ã  100%)
2. â¬‡ï¸ La prÃ©cision test peut diminuer aprÃ¨s un certain seuil
3. ğŸ“Š Un grand Ã©cart entre train et test = **SUR-APPRENTISSAGE**

**Causes :**
- L'arbre "mÃ©morise" les donnÃ©es d'entraÃ®nement
- Les rÃ¨gles deviennent trop spÃ©cifiques
- Perte de capacitÃ© de gÃ©nÃ©ralisation

**Solutions :**
- Limiter la profondeur (`max_depth`)
- Imposer un minimum d'Ã©chantillons par feuille (`min_samples_leaf`)
- Ã‰lagage (pruning)
- Utiliser des mÃ©thodes d'ensemble

### 3.5 Random Forest

Random Forest combine plusieurs arbres de dÃ©cision avec :
- **Bootstrap** : Ã‰chantillonnage avec remise
- **Feature sampling** : SÃ©lection alÃ©atoire d'attributs
- **Vote majoritaire** : AgrÃ©gation des prÃ©dictions

| n_estimators | Train Acc | Test Acc | F1-Score |
|--------------|-----------|----------|----------|
| 10 | ~0.99 | ~0.95 | ~0.96 |
| 50 | ~1.00 | ~0.96 | ~0.97 |
| 100 | ~1.00 | ~0.96 | ~0.97 |
| 200 | ~1.00 | ~0.96 | ~0.97 |

**Avantages :**
- âœ… RÃ©duction du sur-apprentissage
- âœ… Meilleure gÃ©nÃ©ralisation
- âœ… Robuste aux outliers
- âœ… Estimation de l'importance des variables

### 3.6 AdaBoost (Optionnel)

AdaBoost (Adaptive Boosting) est une mÃ©thode de boosting qui :
- EntraÃ®ne des classifieurs faibles sÃ©quentiellement
- Donne plus de poids aux exemples mal classÃ©s
- Combine les classifieurs avec des poids

### 3.7 Comparatif Final

| MÃ©thode | Test Accuracy | InterprÃ©tabilitÃ© |
|---------|---------------|------------------|
| Arbre simple (max_depth=4) | ~94% | âœ… Ã‰levÃ©e |
| Random Forest (n=100) | ~96% | âŒ Faible |
| AdaBoost (n=100) | ~96% | âŒ Faible |

---

## Partie 4 : Application MÃ©tier

### 4.1 Domaine d'Application : Diagnostic MÃ©dical

**Contexte :** Le diagnostic prÃ©coce du cancer du sein est crucial pour le pronostic des patientes. Les mÃ©decins utilisent des biopsies pour analyser les caractÃ©ristiques des cellules tumorales.

**Objectif :** Classifier automatiquement les tumeurs en :
- **BÃ‰NIGNES** (non cancÃ©reuses) - Classe 1
- **MALIGNES** (cancÃ©reuses) - Classe 0

### 4.2 ModÃ¨le Final Retenu

```python
# Arbre de dÃ©cision optimisÃ©
tree_model = DecisionTreeClassifier(
    max_depth=4,
    min_samples_leaf=5,
    random_state=42
)

# Random Forest pour comparaison
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=6,
    random_state=42
)
```

### 4.3 Performances

| ModÃ¨le | Accuracy | PrÃ©cision | Rappel | F1-Score |
|--------|----------|-----------|--------|----------|
| Arbre de dÃ©cision | ~94% | - | - | - |
| Random Forest | ~96% | - | - | - |

### 4.4 Extraction des RÃ¨gles de DÃ©cision

L'arbre de dÃ©cision permet d'extraire des rÃ¨gles interprÃ©tables :

```
|--- worst radius <= 16.80
|   |--- worst concave points <= 0.14
|   |   |--- class: bÃ©nigne
|   |--- worst concave points > 0.14
|   |   |--- class: maligne
|--- worst radius > 16.80
|   |--- class: maligne
```

**InterprÃ©tation mÃ©dicale :**
- Un **rayon maximal > 16.80** indique probablement une tumeur maligne
- Les **points concaves** sont un indicateur clÃ© de malignitÃ©

### 4.5 Top 10 Variables les Plus Importantes

| Rang | Variable | Importance |
|------|----------|------------|
| 1 | worst concave points | ~0.15 |
| 2 | worst perimeter | ~0.12 |
| 3 | worst radius | ~0.11 |
| 4 | mean concave points | ~0.10 |
| 5 | worst area | ~0.08 |
| 6 | mean concavity | ~0.07 |
| 7 | mean perimeter | ~0.06 |
| 8 | area error | ~0.05 |
| 9 | worst concavity | ~0.04 |
| 10 | mean radius | ~0.04 |

### 4.6 Matrice de Confusion

```
              PrÃ©dit
           Maligne  BÃ©nigne
RÃ©el Maligne   XX      XX    (Vrais NÃ©gatifs / Faux Positifs)
     BÃ©nigne   XX      XX    (Faux NÃ©gatifs / Vrais Positifs)
```

> âš ï¸ **Attention** : Les faux nÃ©gatifs (malignes classÃ©es bÃ©nignes) sont particuliÃ¨rement dangereux en contexte mÃ©dical !

### 4.7 Discussion

#### InterprÃ©tabilitÃ© vs Performance

| CritÃ¨re | Arbre de DÃ©cision | Random Forest |
|---------|-------------------|---------------|
| InterprÃ©tabilitÃ© | âœ… TrÃ¨s bonne | âŒ Faible |
| Performance | âš ï¸ Moyenne | âœ… Ã‰levÃ©e |
| Sur-apprentissage | âš ï¸ Risque Ã©levÃ© | âœ… Risque faible |
| Visualisation | âœ… Facile | âŒ Difficile |
| ExplicabilitÃ© | âœ… RÃ¨gles claires | âš ï¸ Importance variables |

#### Limites ObservÃ©es

1. **Zones d'erreur** : Cas limites difficiles Ã  classer
2. **Biais potentiels** : Dataset lÃ©gÃ¨rement dÃ©sÃ©quilibrÃ©
3. **DonnÃ©es manquantes** : Non gÃ©rÃ©es nativement par les arbres
4. **GÃ©nÃ©ralisation** : DÃ©pend de la population d'entraÃ®nement

#### Recommandations pour l'Usage MÃ©dical

- âœ… Utiliser l'arbre comme **outil d'aide** au diagnostic, pas de remplacement
- âœ… Toujours **confirmer** avec l'expertise mÃ©dicale
- âœ… **Actualiser** rÃ©guliÃ¨rement le modÃ¨le avec de nouvelles donnÃ©es
- âœ… Porter une attention particuliÃ¨re aux **faux nÃ©gatifs**

---

## Conclusion

### RÃ©capitulatif des Apprentissages

Ce projet a permis de maÃ®triser les aspects suivants :

| Aspect | CompÃ©tences Acquises |
|--------|---------------------|
| **ThÃ©orie** | ComprÃ©hension des mesures d'impuretÃ© (Gini, Entropie) |
| **Algorithmique** | ImplÃ©mentation rÃ©cursive d'un arbre de dÃ©cision |
| **Analyse** | DÃ©tection et comprÃ©hension du sur-apprentissage |
| **Comparaison** | Ã‰valuation de diffÃ©rents modÃ¨les (Arbre, RF, AdaBoost) |
| **Application** | RÃ©solution d'un problÃ¨me rÃ©el de diagnostic mÃ©dical |
| **InterprÃ©tation** | Extraction et explication de rÃ¨gles mÃ©tier |

### Points ClÃ©s Ã  Retenir

1. **Les arbres de dÃ©cision** sont des modÃ¨les puissants et interprÃ©tables
2. **Le sur-apprentissage** est un risque majeur Ã  contrÃ´ler
3. **Les mÃ©thodes d'ensemble** (Random Forest) amÃ©liorent les performances
4. **L'interprÃ©tabilitÃ©** est cruciale dans les domaines sensibles comme la mÃ©decine
5. **Le compromis biais-variance** guide le choix des hyperparamÃ¨tres

### Perspectives d'AmÃ©lioration

- ğŸ”„ Validation croisÃ©e (k-fold) pour une Ã©valuation plus robuste
- ğŸ¯ Optimisation des hyperparamÃ¨tres (GridSearchCV)
- ğŸ“Š Analyse des courbes ROC et AUC
- ğŸ” Techniques d'explicabilitÃ© avancÃ©es (SHAP, LIME)
- ğŸ§ª Test sur d'autres datasets mÃ©dicaux

---

## Annexe : Structure du Code

```
Projet_Arbres_Decision.ipynb
â”‚
â”œâ”€â”€ ğŸ“¦ Imports et Configuration
â”‚   â””â”€â”€ numpy, pandas, matplotlib, sklearn
â”‚
â”œâ”€â”€ ğŸ“– Partie 1 : Concepts ThÃ©oriques
â”‚   â”œâ”€â”€ DÃ©finitions markdown
â”‚   â”œâ”€â”€ gini()
â”‚   â”œâ”€â”€ entropy()
â”‚   â”œâ”€â”€ classification_error()
â”‚   â””â”€â”€ Visualisation des courbes d'impuretÃ©
â”‚
â”œâ”€â”€ ğŸ”§ Partie 2 : Implementation From Scratch
â”‚   â”œâ”€â”€ Dataset crÃ©dit simplifiÃ©
â”‚   â”œâ”€â”€ class Node
â”‚   â”œâ”€â”€ get_class_counts()
â”‚   â”œâ”€â”€ find_best_split()
â”‚   â”œâ”€â”€ build_tree()
â”‚   â”œâ”€â”€ predict_one() / predict()
â”‚   â”œâ”€â”€ print_tree()
â”‚   â””â”€â”€ Comparaison sklearn
â”‚
â”œâ”€â”€ ğŸ“ˆ Partie 3 : Extensions
â”‚   â”œâ”€â”€ Chargement Breast Cancer
â”‚   â”œâ”€â”€ Train/Test split
â”‚   â”œâ”€â”€ Analyse profondeur
â”‚   â”œâ”€â”€ Graphique overfitting
â”‚   â”œâ”€â”€ Random Forest
â”‚   â””â”€â”€ AdaBoost
â”‚
â””â”€â”€ ğŸ¥ Partie 4 : Application MÃ©tier
    â”œâ”€â”€ Contexte mÃ©dical
    â”œâ”€â”€ ModÃ¨le final
    â”œâ”€â”€ RÃ¨gles de dÃ©cision
    â”œâ”€â”€ Importance des variables
    â”œâ”€â”€ Matrice de confusion
    â””â”€â”€ Discussion et recommandations
```

---

*Rapport gÃ©nÃ©rÃ© automatiquement - Projet Data Mining 2024-2025*
