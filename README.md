# ğŸŒ³ Mini Projet : Arbres de DÃ©cision

## ğŸ“‹ Description

Ce projet explore les **arbres de dÃ©cision** en machine learning, de la thÃ©orie Ã  l'implÃ©mentation pratique. Il couvre les concepts fondamentaux, l'implÃ©mentation from scratch, les extensions (Random Forest, Gradient Boosting), et une application sur un dataset rÃ©el.

## ğŸ“ Structure du Projet

```
â”œâ”€â”€ Projet_Arbres_Decision.ipynb    # Notebook principal avec tout le code
â”œâ”€â”€ Rapport_Arbres_Decision.md      # Rapport dÃ©taillÃ© du projet
â”œâ”€â”€ impurete_comparison.png         # Visualisation des mesures d'impuretÃ©
â””â”€â”€ README.md                       # Ce fichier
```

## ğŸ¯ Objectifs du Projet

1. **Partie ThÃ©orique** : Comprendre les fondements mathÃ©matiques des arbres de dÃ©cision
   - Mesures d'impuretÃ© (Gini, Entropie, Erreur de classification)
   - CritÃ¨res de division
   - Algorithmes CART, ID3, C4.5

2. **ImplÃ©mentation From Scratch** : Coder un arbre de dÃ©cision sans librairies ML
   - Structure rÃ©cursive de l'arbre
   - Calcul du gain d'information
   - PrÃ©diction et visualisation

3. **Extensions** : Explorer les mÃ©thodes d'ensemble
   - Random Forest
   - Gradient Boosting
   - Comparaison des performances

4. **Application Pratique** : Dataset Iris
   - PrÃ©traitement des donnÃ©es
   - EntraÃ®nement et Ã©valuation
   - Analyse des rÃ©sultats

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.x**
- **NumPy** : Calculs numÃ©riques
- **Pandas** : Manipulation de donnÃ©es
- **Matplotlib** : Visualisations
- **Scikit-learn** : Comparaison avec implÃ©mentations standards

## ğŸš€ Utilisation

1. Cloner le repository :
```bash
git clone https://github.com/soukainanidlahsen/Mini_Projet_Arbres-de-decision.git
```

2. Installer les dÃ©pendances :
```bash
pip install numpy pandas matplotlib scikit-learn jupyter
```

3. Lancer le notebook :
```bash
jupyter notebook Projet_Arbres_Decision.ipynb
```

## ğŸ“Š RÃ©sultats ClÃ©s

- ImplÃ©mentation fonctionnelle d'un arbre de dÃ©cision from scratch
- Comparaison des mesures d'impuretÃ© (Gini vs Entropie)
- Analyse des performances sur le dataset Iris
- DÃ©monstration des avantages des mÃ©thodes d'ensemble

## ğŸ‘¤ Auteur

**Soukaina Nid Lahsen**

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans un cadre acadÃ©mique.

---
*Projet rÃ©alisÃ© dans le cadre du cours de Data Mining / Machine Learning*
